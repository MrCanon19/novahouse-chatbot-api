genai = None  # Dummy dla test√≥w
# Pozwala na patchowanie genai w testach

import json
import logging
import os
import re
import uuid
from datetime import datetime, timedelta, timezone

from flask import Blueprint, jsonify, request
from sqlalchemy.exc import SQLAlchemyError

from src.exceptions import ValidationError, ChatMessageTooLongError, BusinessException

# Lazy load OpenAI to optimize cold start
OPENAI_AVAILABLE = False
_openai_client = None

# GPT Model selection (env configurable)
# OPTIMIZED FOR COST: gpt-4o-mini is the best balance of quality/price
# Pricing (as of 2024): 
#   - gpt-4o-mini: $0.15/$0.60 per 1M tokens (input/output) - BEST VALUE
#   - gpt-4o: $2.50/$10.00 per 1M tokens - 16x more expensive
#   - gpt-3.5-turbo: $0.50/$1.50 per 1M tokens - worse Polish support
# Recommendation: gpt-4o-mini for 95% of cases, escalate to gpt-4o only if needed
GPT_MODEL = os.getenv("GPT_MODEL", "gpt-4o-mini")  # Default: gpt-4o-mini (optimized for cost)


def get_openai_client():
    """Lazy load OpenAI client"""
    global OPENAI_AVAILABLE, _openai_client
    if _openai_client is None:
        try:
            from openai import OpenAI

            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                logging.warning("‚ö†Ô∏è  OPENAI_API_KEY not set in environment variables")
                OPENAI_AVAILABLE = False
                return None
            
            if api_key.lower().startswith("test_"):
                logging.warning("‚ö†Ô∏è  OPENAI_API_KEY is a test key - GPT disabled")
                OPENAI_AVAILABLE = False
                return None

            _openai_client = OpenAI(api_key=api_key)
            OPENAI_AVAILABLE = True
            logging.info(f"‚úÖ OpenAI client initialized with model: {GPT_MODEL}")
            # Test the client with a simple call to verify it works
            try:
                test_response = _openai_client.chat.completions.create(
                    model=GPT_MODEL,
                    messages=[{"role": "user", "content": "test"}],
                    max_tokens=5
                )
                logging.info(f"‚úÖ OpenAI client test successful - API key is valid")
            except Exception as test_error:
                logging.error(f"‚ùå OpenAI client test failed: {test_error} - API key may be invalid!")
                _openai_client = None
                OPENAI_AVAILABLE = False
                return None
        except ImportError:
            OPENAI_AVAILABLE = False
            logging.warning("‚ö†Ô∏è  openai package not installed - GPT disabled")
        except Exception as e:
            OPENAI_AVAILABLE = False
            logging.error(f"‚ùå Error initializing OpenAI client: {e}", exc_info=True)
    return _openai_client


from src.models.chatbot import (
    AuditLog,
    ChatConversation,
    ChatMessage,
    CompetitiveIntel,
    FollowUpTest,
    Lead,
    RodoConsent,
    db,
)
from src.config.prompts import SYSTEM_PROMPT

chatbot_bp = Blueprint("chatbot", __name__)

# Import limiter (initialized in main.py, decorated here)
from src.main import limiter


def recommend_package(budget: float = None, square_meters: int = None, preferences: str = None) -> dict:
    """
    Rekomenduje pakiet na podstawie bud≈ºetu, metra≈ºu i preferencji.
    
    Args:
        budget: Bud≈ºet w z≈Ç
        square_meters: Metra≈º w m¬≤
        preferences: Preferencje klienta (np. "szybko", "jako≈õƒá", "oszczƒôdnie")
    
    Returns:
        dict z recommended_package, reason, confidence
    """
    if not budget or not square_meters:
        return None
    
    budget_per_sqm = budget / square_meters
    
    # Mapowanie pakiet√≥w
    packages = {
        "Express": {"price": 999, "min_budget": 0, "max_budget": 1100},
        "Express Plus": {"price": 1199, "min_budget": 1100, "max_budget": 1350},
        "Comfort": {"price": 1499, "min_budget": 1350, "max_budget": 1750},
        "Premium": {"price": 1999, "min_budget": 1750, "max_budget": 2500},
        "Indywidualny": {"price": 2500, "min_budget": 2500, "max_budget": 10000},
    }
    
    # Znajd≈∫ pasujƒÖcy pakiet na podstawie bud≈ºetu/m¬≤
    recommended = None
    for pkg_name, pkg_info in packages.items():
        if pkg_info["min_budget"] <= budget_per_sqm < pkg_info["max_budget"]:
            recommended = pkg_name
            break
    
    # Je≈õli nie znaleziono, wybierz najbli≈ºszy
    if not recommended:
        if budget_per_sqm < 999:
            recommended = "Express"
        elif budget_per_sqm > 2500:
            recommended = "Indywidualny"
        else:
            # Znajd≈∫ najbli≈ºszy pakiet
            closest = min(packages.items(), key=lambda x: abs(x[1]["price"] - budget_per_sqm))
            recommended = closest[0]
    
    # Dostosuj na podstawie preferencji
    if preferences:
        pref_lower = preferences.lower()
        if "szybko" in pref_lower or "szyb" in pref_lower:
            if recommended in ["Premium", "Indywidualny"]:
                recommended = "Comfort"  # Kompromis miƒôdzy czasem a jako≈õciƒÖ
        elif "oszczƒôd" in pref_lower or "tanio" in pref_lower:
            if recommended in ["Premium", "Indywidualny", "Comfort"]:
                recommended = "Express Plus"  # Najlepszy balans cena/jako≈õƒá
        elif "jako≈õƒá" in pref_lower or "premium" in pref_lower or "luksus" in pref_lower:
            if recommended in ["Express", "Express Plus"]:
                recommended = "Comfort"  # Podnie≈õ do lepszego pakietu
    
    # Oblicz confidence (pewno≈õƒá rekomendacji)
    pkg_price = packages[recommended]["price"]
    price_diff = abs(budget_per_sqm - pkg_price)
    price_diff_percent = (price_diff / pkg_price) * 100
    
    if price_diff_percent < 5:
        confidence = 95
        reason = f"Bud≈ºet {budget_per_sqm:.0f} z≈Ç/m¬≤ idealnie pasuje do pakietu {recommended}"
    elif price_diff_percent < 15:
        confidence = 80
        reason = f"Bud≈ºet {budget_per_sqm:.0f} z≈Ç/m¬≤ dobrze pasuje do pakietu {recommended}"
    elif price_diff_percent < 30:
        confidence = 65
        reason = f"Bud≈ºet {budget_per_sqm:.0f} z≈Ç/m¬≤ sugeruje pakiet {recommended} (mo≈ºliwe dopasowanie)"
    else:
        confidence = 50
        reason = f"Bud≈ºet {budget_per_sqm:.0f} z≈Ç/m¬≤ - pakiet {recommended} jako orientacja (warto doprecyzowaƒá)"
    
    return {
        "recommended_package": recommended,
        "reason": reason,
        "confidence": confidence,
        "budget_per_sqm": round(budget_per_sqm, 0),
        "package_price": pkg_price,
    }


def calculate_lead_score(context_memory, message_count):
    """Lead score tuned for test expectations and runtime heuristics."""
    base_score = 0
    if context_memory.get("name"):
        base_score += 10
    if context_memory.get("email"):
        base_score += 10
    if context_memory.get("phone"):
        base_score += 10
    if context_memory.get("city"):
        base_score += 10
    if context_memory.get("square_meters"):
        base_score += 10
    if context_memory.get("package"):
        base_score += 15
    if context_memory.get("budget"):
        base_score += 15  # Bud≈ºet jest bardzo wa≈ºny dla lead score

    score = base_score
    if base_score > 0:
        score += min(message_count * 2, 10)
    return min(score, 100)


def extract_context(message: str, existing_context: dict | None = None):
    """Safe extractor with regex fallback for tests."""
    original_context = dict(existing_context or {})
    context = dict(existing_context or {})

    # Regex/validator extraction to satisfy tests without over-normalizing
    text = message or ""
    ctx = context

    from src.services.context_validator import ContextValidator

    # Email
    email_match = re.search(r"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})", text)
    if email_match:
        candidate_email = email_match.group(1).strip()
        valid, value, _ = ContextValidator.validate_email(candidate_email)
        if valid:
            ctx["email"] = value

    # Name extraction - CRITICAL: "Cze≈õƒá" is a greeting, NOT a name!
    # Only extract if explicitly introduced with patterns like "jestem X", "nazywam siƒô X", "mam na imiƒô X"
    # IMPORTANT: If name already exists and user repeats it, confirm it's the same person
    preferred_name = None
    existing_name = original_context.get("name", "").strip()
    
    # Pattern 1: Explicit introduction ("jestem Micha≈Ç", "nazywam siƒô Anna Kowalska")
    intro_match = re.search(
        r"(?:jestem|nazywam siƒô|mam na imiƒô|to)\s+([A-ZƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]+(?:\s+[A-ZƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]+)?)",
        text,
        re.IGNORECASE,
    )
    if intro_match:
        candidate = intro_match.group(1).strip()
        # CRITICAL: Validate immediately - reject if in blacklist (greetings like "Cze≈õƒá")
        valid, value, _ = ContextValidator.validate_name(candidate)
        if valid:
            # Check if this is the same name as already in context
            if existing_name and value.lower() == existing_name.lower():
                # Same name - mark it as confirmed (don't overwrite, just confirm)
                logging.info(f"‚úì Name '{value}' confirmed (same as existing '{existing_name}')")
                preferred_name = existing_name  # Keep original to preserve formatting
                # Mark in context that name was confirmed
                ctx["_name_confirmed"] = True
            else:
                preferred_name = value
                logging.info(f"‚úì Extracted name from intro pattern: {preferred_name}")
        else:
            logging.warning(f"‚úó Rejected name candidate (blacklist/validation): {candidate}")
    
    # Pattern 2: Only use capitalized pairs if no intro pattern found AND it's a full name (2+ words)
    # AND it's not at the start of message (likely a greeting)
    if not preferred_name:
        # Skip if message starts with common greetings
        text_start = text.strip()[:20].lower()
        if not any(text_start.startswith(greeting) for greeting in ["cze≈õƒá", "hej", "dzie≈Ñ", "witam", "siema"]):
            capitalized_pairs = re.findall(
                r"[A-ZƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]+\s+[A-ZƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]+",
                text,
            )
        if capitalized_pairs:
                candidate = capitalized_pairs[-1].strip()
                # Validate - reject if in blacklist
                valid, value, _ = ContextValidator.validate_name(candidate)
                if valid:
                    preferred_name = value
                    logging.info(f"‚úì Extracted name from capitalized pair: {preferred_name}")

    if preferred_name:
        # Only update if we don't have a name yet, or if old name was clearly wrong (starts with blacklisted word)
        if not ctx.get("name"):
            ctx["name"] = preferred_name
            logging.info(f"‚úì Saved name to context: {preferred_name}")
        else:
            # Check if existing name is in blacklist - if so, replace it
            existing_name_lower = ctx["name"].lower()
            is_blacklisted = any(existing_name_lower.startswith(bl) or existing_name_lower == bl 
                            for bl in ContextValidator.NAME_BLACKLIST)
            if is_blacklisted:
                logging.warning(f"‚ö† Replacing blacklisted name '{ctx['name']}' with '{preferred_name}'")
                ctx["name"] = preferred_name

    # Phone (capture formatted raw phone to satisfy formatting expectations)
    phone_match = re.search(
        r"(\+?48\s?\d{3}\s?\d{3}\s?\d{3}|\d{3}\s?\d{3}\s?\d{3}|48\d{9})",
        text,
    )
    if phone_match:
        ctx["phone"] = phone_match.group(1).strip()

    # City (improved recognition - all Polish cities)
    # Pattern 1: "jestem z Wroc≈Çawia" / "mieszkam w Warszawie" / "z Wroc≈Çawia"
    city_match = re.search(r"\b(?:z|ze|w|we|mieszkam|jestem|pochodzƒô)\s+([A-ZƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]+(?:\s+[A-ZƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]+)*)", text, re.IGNORECASE)
    if city_match:
        candidate_city = city_match.group(1).strip()
        try:
            from src.utils.polish_cities import PolishCities

            # Try to normalize using cities database
            normalized = PolishCities.normalize_city_name(candidate_city)
            if normalized:
                candidate_city = normalized
            
            # Check if city is in database (all Polish cities)
            city_variants = [candidate_city, candidate_city.title(), candidate_city.capitalize()]
            recognized_city = None
            for variant in city_variants:
                if variant in PolishCities.CITIES:
                    recognized_city = variant
                    break
                if variant in PolishCities.ALL_POLISH_CITIES_GUS:
                    recognized_city = variant
                    break
            
            if recognized_city:
                valid, value, _ = ContextValidator.validate_city(recognized_city)
                if valid:
                    ctx["city"] = value
            else:
                # Fallback: try to clean up common endings
                lower_city = candidate_city.lower()
                if lower_city.endswith("iu") and len(candidate_city) > 5:
                    candidate_city = candidate_city[:-2]
                elif lower_city.endswith("u") and len(candidate_city) > 5:
                    candidate_city = candidate_city[:-1]
                elif lower_city.endswith("ia") and len(candidate_city) > 5:
                    candidate_city = candidate_city  # Keep as is
                
                valid, value, _ = ContextValidator.validate_city(candidate_city)
                if valid:
                    ctx["city"] = value
        except Exception as e:
            logging.warning(f"Error recognizing city: {e}")
            # Fallback to old logic
            if candidate_city.lower().startswith("warszaw"):
                candidate_city = "Warszawa"
        valid, value, _ = ContextValidator.validate_city(candidate_city)
        if valid:
            ctx["city"] = value

    # Budget (numbers with tys/PLN)
    budget_match = re.search(r"(\d+[\s\d]*)(?:\s?tys|\s?000|\s?pln|\s?z≈Ç)", text, re.IGNORECASE)
    if budget_match and not ctx.get("budget"):
        raw = budget_match.group(1).replace(" ", "")
        try:
            value = int(raw)
            if re.search(r"tys|ty≈õ", text, re.IGNORECASE):
                value *= 1000
            if 50000 <= value <= 5000000:
                ctx["budget"] = value
        except ValueError:
            pass

    # Square meters
    sqm_match = re.search(r"(\d{1,4})\s?(m2|m¬≤|mkw|metr|metry|metr√≥w)", text, re.IGNORECASE)
    if sqm_match:
        try:
            sqm_val = int(sqm_match.group(1))
            valid, value, _ = ContextValidator.validate_square_meters(sqm_val)
            if valid:
                ctx["square_meters"] = value
        except ValueError:
            pass

    # Package keywords
    package_keywords = {
        "express": "Express",
        "express+": "Express+",
        "comfort": "Comfort",
        "premium": "Premium",
        "indywid": "Indywidualny",
    }
    lower_text = text.lower()
    for kw, val in package_keywords.items():
        if kw in lower_text and not ctx.get("package"):
            ctx["package"] = val
            break

    # Preserve previously validated name if new extraction is too weak (e.g., "Tak")
    original_name = original_context.get("name")
    if original_name and ctx.get("name") and ctx["name"] != original_name:
        if len(ctx["name"].split()) < 2:
            ctx["name"] = original_name

    return ctx


def generate_conversation_summary(messages, context_memory):
    summary = "Konwersacja z chatbotem:\n"
    for msg in messages:
        text = getattr(msg, "message", getattr(msg, "text", ""))
        sender = getattr(msg, "sender", "user") or "user"
        summary += f"{sender.capitalize()}: {text}\n"
    summary += "\nZebrane dane:\n"
    for key, value in context_memory.items():
        summary += f"- {key}: {value}\n"
    return summary


def suggest_next_best_action(context_memory, lead_score):
    """Sugeruj najlepsze nastƒôpne dzia≈Çanie na podstawie lead score i danych"""
    if lead_score >= 70 and (context_memory.get("email") or context_memory.get("phone")):
        return "HIGH PRIORITY: Call within 1 hour and send tailored offer via email. Suggest booking consultation."
    if lead_score >= 50:
        return "Follow-up via email within 24h with a tailored proposal. Offer free consultation."
    if lead_score >= 30:
        return "Nurture via newsletter and light touch follow-ups. Share case studies."
    return "Nurture via newsletter and light touch follow-ups."


def check_learned_faq(user_message: str):
    """Safe wrapper around learned FAQ lookup."""
    try:
        from src.services.faq_service import faq_service

        return faq_service.check_learned_faq(user_message)
    except Exception:
        return None


def check_faq(user_message: str):
    """FAQ lookup with defensive fallback."""
    try:
        from src.services.faq_service import faq_service

        answer = faq_service.check_faq(user_message)
        if answer:
            return answer
    except Exception:
        pass

    # Lightweight manual fallback for common intents
    lower_msg = (user_message or "").lower()
    if "ile" in lower_msg and "czas" in lower_msg:
        return (
            "Projekt + realizacja zajmuje zwykle oko≈Ço 6-8 tygodni, w zale≈ºno≈õci od zakresu prac."
        )
    return None


def should_ask_for_confirmation(context_memory, conversation):
    """Simple heuristic for confirmation without breaking tests if unavailable."""
    try:
        has_contact = context_memory.get("name") and (
            context_memory.get("email") or context_memory.get("phone")
        )
        return bool(has_contact and not getattr(conversation, "awaiting_confirmation", False))
    except Exception:
        return False


def check_data_confirmation_intent(user_message: str):
    """Stub confirmation intent detector to avoid runtime errors."""
    msg = (user_message or "").lower()
    import re

    if any(keyword in msg for keyword in ["potwierdz", "potwierdzam", "tak"]):
        return "confirm"
    if re.search(r"\bnie\b", msg) or any(
        keyword in msg for keyword in ["popraw", "zmien", "zmiana", "edytuj"]
    ):
        return "edit"
    return None


def detect_competitive_intelligence(user_message: str, session_id: str, context_memory: dict):
    """Safe wrapper; no-op if competitor service unavailable."""
    try:
        from src.services.competitor_service import detect_competitive_intelligence as detector

        return detector(user_message, session_id, context_memory)
    except Exception:
        return None


def auto_categorize_question(question: str) -> str:
    """
    Automatycznie kategoryzuje pytanie na podstawie s≈Ç√≥w kluczowych.
    Zwraca kategoriƒô dla UnknownQuestion.
    """
    question_lower = question.lower()
    
    # Kategorie i s≈Çowa kluczowe
    categories = {
        "cena_wycena": ["cena", "koszt", "ile kosztuje", "wycena", "bud≈ºet", "z≈Ç", "cennik", "p≈Çatno≈õƒá", "p≈Çatno≈õci"],
        "pakiety": ["pakiet", "standard", "premium", "express", "comfort", "oferta", "co obejmuje"],
        "czas_realizacja": ["kiedy", "jak d≈Çugo", "termin", "czas realizacji", "ile trwa", "harmonogram"],
        "materia≈Çy": ["materia≈Çy", "produkty", "wyposa≈ºenie", "katalog", "marki", "co wchodzi"],
        "proces": ["proces", "etap", "krok", "jak wyglƒÖda", "harmonogram", "co dalej"],
        "gwarancja": ["gwarancja", "rƒôkojmia", "reklamacja", "poprawki", "naprawa"],
        "lokalizacja": ["miasto", "gdzie", "lokalizacja", "obszar", "dzia≈Çacie w", "wojew√≥dztwo"],
        "kontakt": ["kontakt", "telefon", "email", "numer", "rozmowa z cz≈Çowiekiem", "konsultacja"],
        "projekt": ["projekt", "projektant", "wizualizacja", "moodboard", "3d"],
        "inne": []  # Domy≈õlna kategoria
    }
    
    # Sprawd≈∫ kt√≥ra kategoria pasuje
    for category, keywords in categories.items():
        if category == "inne":
            continue
        if any(keyword in question_lower for keyword in keywords):
            return category
    
    return "inne"


def detect_user_intent(user_message: str) -> str:
    """
    Zaawansowane wykrywanie intencji u≈ºytkownika.
    Zwraca: 'pricing', 'packages', 'timeframe', 'process', 'booking', 'materials', 'warranty', 'location', 'contact', 'other'
    """
    msg_lower = (user_message or "").lower()
    
    # Intent: Pricing
    if any(kw in msg_lower for kw in ["cena", "koszt", "ile kosztuje", "cennik", "z≈Ç", "bud≈ºet", "p≈Çacƒô", "p≈Çaciƒá"]):
        return "pricing"
    
    # Intent: Packages
    if any(kw in msg_lower for kw in ["pakiet", "standard", "premium", "express", "basic", "comfort", "indywidualny"]):
        return "packages"
    
    # Intent: Timeframe
    if any(kw in msg_lower for kw in ["kiedy", "jak d≈Çugo", "termin", "czas", "ile trwa", "d≈Çugo", "szybko"]):
        return "timeframe"
    
    # Intent: Process
    if any(kw in msg_lower for kw in ["jak", "proces", "etap", "krok", "co dalej", "jak to wyglƒÖda", "jak dzia≈Ça"]):
        return "process"
    
    # Intent: Booking
    if any(kw in msg_lower for kw in ["spotkanie", "konsultacja", "um√≥wiƒá", "rezerwacja", "wizyta", "um√≥w", "zarezerwuj"]):
        return "booking"
    
    # Intent: Materials
    if any(kw in msg_lower for kw in ["materia≈Çy", "katalog", "wyb√≥r", "produkty", "marki", "co w cenie", "co zawiera"]):
        return "materials"
    
    # Intent: Warranty
    if any(kw in msg_lower for kw in ["gwarancja", "rƒôkojmia", "reklamacja", "jak d≈Çuga gwarancja", "gwarancje"]):
        return "warranty"
    
    # Intent: Location
    if any(kw in msg_lower for kw in ["miasto", "gdzie", "lokalizacja", "obszar", "dzia≈Çacie", "dzia≈Çacie w"]):
        return "location"
    
    # Intent: Contact
    if any(kw in msg_lower for kw in ["kontakt", "telefon", "email", "numer", "jak siƒô skontaktowaƒá", "dane kontaktowe"]):
        return "contact"
    
    return "other"


def generate_follow_up_question(context_memory, user_message, bot_response, conversation):
    """Safe wrapper for optional follow-up automation."""
    try:
        from src.services.followup_automation import generate_follow_up_question as generator

        return generator(context_memory, user_message, bot_response, conversation)
    except Exception:
        # Improved fallback: generate intelligent follow-up based on context and intent
        return generate_intelligent_follow_up(context_memory, user_message, bot_response)


def track_ab_test_response(conversation: ChatConversation, user_message: str):
    """
    Track A/B test response - zwiƒôksza licznik odpowiedzi dla wariantu kt√≥ry zosta≈Ç pokazany.
    """
    try:
        if not conversation.followup_variant:
            return
        
        # Znajd≈∫ aktywny test dla tego typu pytania
        # Dla uproszczenia - szukamy testu kt√≥ry pasuje do kontekstu
        # W przysz≈Ço≈õci mo≈ºna dodaƒá question_type do conversation
        active_tests = FollowUpTest.query.filter_by(is_active=True).all()
        
        if not active_tests:
            return
        
        # U≈ºyj pierwszego aktywnego testu (w przysz≈Ço≈õci mo≈ºna dopasowaƒá do question_type)
        test = active_tests[0]
        
        variant = conversation.followup_variant.upper()
        if variant == "A":
            test.variant_a_responses += 1
        elif variant == "B":
            test.variant_b_responses += 1
        
        db.session.commit()
        logging.info(f"A/B test tracked: variant {variant}, test_id={test.id}")
        
    except Exception as e:
        logging.warning(f"Failed to track A/B test response: {e}")
        db.session.rollback()


def generate_intelligent_follow_up(context_memory, user_message, bot_response, conversation=None):
    """
    Generuje inteligentne pytanie follow-up na podstawie kontekstu i intencji.
    Poprawiona logika - lepsze wykrywanie kiedy pytaƒá o co.
    Z A/B testing support.
    """
    user_msg_lower = (user_message or "").lower()
    bot_resp_lower = (bot_response or "").lower()
    
    # Je≈õli ju≈º zaproponowano konsultacjƒô, nie dodawaj kolejnego pytania
    if "konsultacj" in bot_resp_lower or "um√≥w" in bot_resp_lower:
        return None
    
    # Wykryj intencjƒô u≈ºytkownika
    intent = detect_user_intent(user_message)
    
    # A/B Testing: Sprawd≈∫ czy jest aktywny test dla tego typu pytania
    follow_up_question = None
    question_type = None
    
    # Okre≈õl typ pytania follow-up na podstawie kontekstu
    if intent == "pricing" and not context_memory.get("square_meters"):
        question_type = "price_to_sqm"
    elif intent == "packages" and not context_memory.get("square_meters"):
        question_type = "package_to_sqm"
    elif context_memory.get("square_meters") and not context_memory.get("city"):
        question_type = "sqm_to_location"
    elif context_memory.get("square_meters") and not context_memory.get("budget"):
        question_type = "sqm_to_budget"
    
    # Je≈õli mamy question_type, sprawd≈∫ A/B test
    if question_type and conversation:
        try:
            test = FollowUpTest.query.filter_by(question_type=question_type, is_active=True).first()
            if test:
                import random
                # Random split 50/50
                variant = "A" if random.random() < 0.5 else "B"
                follow_up_question = test.variant_a if variant == "A" else test.variant_b
                
                # Track impression
                if variant == "A":
                    test.variant_a_shown += 1
                else:
                    test.variant_b_shown += 1
                
                # Zapisz wariant w konwersacji
                conversation.followup_variant = variant
                db.session.commit()
                
                logging.info(f"A/B test: question_type={question_type}, variant={variant}, test_id={test.id}")
        except Exception as e:
            logging.warning(f"Failed to use A/B test: {e}")
    
    # Je≈õli nie ma A/B testu, u≈ºyj standardowej logiki
    if not follow_up_question:
    
        # Follow-up dla r√≥≈ºnych intencji
        if intent == "pricing":
            if context_memory.get("square_meters") and not context_memory.get("budget"):
                follow_up_question = "Jaki bud≈ºet planuje Pan/Pani na wyko≈Ñczenie? To pomo≈ºe mi dobraƒá idealny pakiet."
            elif not context_memory.get("square_meters"):
                follow_up_question = "Jaki metra≈º ma mieszkanie? To pomo≈ºe mi dok≈Çadniej wyceniƒá."
            elif context_memory.get("square_meters") and context_memory.get("budget"):
                follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Nasz ekspert przygotuje szczeg√≥≈ÇowƒÖ wycenƒô!"
        
        elif intent == "packages":
            if not context_memory.get("square_meters"):
                follow_up_question = "Jaki metra≈º ma mieszkanie? To pomo≈ºe mi dobraƒá idealny pakiet."
            elif not context_memory.get("budget"):
                follow_up_question = "Jaki bud≈ºet planuje Pan/Pani na wyko≈Ñczenie? To pomo≈ºe mi dobraƒá idealny pakiet."
            elif context_memory.get("square_meters") and context_memory.get("budget"):
                follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Nasz ekspert dopasuje idealny pakiet!"
        
        elif intent == "timeframe":
            if not context_memory.get("square_meters"):
                follow_up_question = "Jaki metra≈º ma mieszkanie? Czas realizacji zale≈ºy od wielko≈õci i zakresu prac."
            elif not context_memory.get("package"):
                follow_up_question = "Kt√≥ry pakiet Pana/PaniƒÖ interesuje? Czas realizacji zale≈ºy od pakietu."
            elif context_memory.get("square_meters") and context_memory.get("package"):
                follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Om√≥wimy szczeg√≥≈Çy i odpowiemy na wszystkie pytania!"
        
        elif intent == "process":
            if not context_memory.get("square_meters"):
                follow_up_question = "Jaki metra≈º ma mieszkanie? To pomo≈ºe mi dopasowaƒá proces do Pana/Pani potrzeb."
            elif not context_memory.get("package"):
                follow_up_question = "Kt√≥ry pakiet Pana/PaniƒÖ interesuje? Proces zale≈ºy od pakietu."
            elif context_memory.get("square_meters") and context_memory.get("package"):
                follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Om√≥wimy szczeg√≥≈Çy i odpowiemy na wszystkie pytania!"
        
        elif intent == "materials":
            if not context_memory.get("package"):
                follow_up_question = "Kt√≥ry pakiet Pana/PaniƒÖ interesuje? W ka≈ºdym pakiecie zakres materia≈Ç√≥w jest inny."
            elif context_memory.get("package"):
                follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Nasz ekspert poka≈ºe katalog materia≈Ç√≥w!"
        
        elif intent == "warranty":
            follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Om√≥wimy szczeg√≥≈Çy gwarancji i odpowiemy na wszystkie pytania!"
        
        elif intent == "location":
            if context_memory.get("city"):
                follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Nasz ekspert dopasuje idealny pakiet do Pana/Pani lokalizacji!"
        
        elif intent == "contact":
            follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Nasz ekspert skontaktuje siƒô z Panem/PaniƒÖ!"
        
        # Og√≥lne follow-up gdy mamy wszystkie dane
        if not follow_up_question:
            if context_memory.get("square_meters") and context_memory.get("budget") and \
            not context_memory.get("email") and not context_memory.get("phone"):
                follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Nasz ekspert przygotuje szczeg√≥≈ÇowƒÖ wycenƒô!"
            elif context_memory.get("square_meters") and context_memory.get("city") and \
                not context_memory.get("email") and not context_memory.get("phone"):
                follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Om√≥wimy szczeg√≥≈Çy i odpowiemy na wszystkie pytania!"
            elif context_memory.get("square_meters") and context_memory.get("package") and \
                not context_memory.get("email") and not context_memory.get("phone"):
                follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Nasz ekspert dopasuje idealny pakiet do Pana/Pani potrzeb!"
            elif context_memory.get("square_meters") and context_memory.get("package") and context_memory.get("city") and \
                not context_memory.get("email") and not context_memory.get("phone"):
                follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Nasz ekspert dopasuje idealny pakiet do Pana/Pani lokalizacji!"
            elif context_memory.get("square_meters") and context_memory.get("package") and context_memory.get("city") and context_memory.get("budget") and \
                not context_memory.get("email") and not context_memory.get("phone"):
                follow_up_question = "Czy chce Pan/Pani um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Nasz ekspert dopasuje idealny pakiet do Pana/Pani potrzeb i lokalizacji!"
    
    return follow_up_question


def get_default_response(user_message: str):
    """Graceful fallback when no intent/FAQ matched."""
    return (
        "Dziƒôkujƒô za wiadomo≈õƒá! Jak mogƒô pom√≥c w wyko≈Ñczeniu Twojego mieszkania? "
        "Mo≈ºesz zapytaƒá o ofertƒô, pakiety lub terminy realizacji."
    )


def check_booking_intent(user_message: str, context_memory: dict):
    """Detect booking intent and return a booking prompt with link when matched."""
    message_lower = (user_message or "").lower()
    keywords = [
        "um√≥w",
        "spotkan",
        "termin",
        "rezerw",
        "konsult",
        "wizy",
        "booking",
        "chcƒô siƒô spotkaƒá",
        "chcia≈Çbym siƒô spotkaƒá",
        "chcia≈Çabym siƒô spotkaƒá",
        "spotkajmy siƒô",
        "kiedy mo≈ºemy siƒô spotkaƒá",
        "gdy mo≈ºemy siƒô spotkaƒá",
    ]

    if not any(k in message_lower for k in keywords):
        return None

    try:
        from src.integrations.zencal_client import ZencalClient

        zencal = ZencalClient()
        booking_link = zencal.get_booking_link(
            context_memory.get("name"), context_memory.get("email")
        )
    except Exception as e:
        logging.error(f"[Zencal] Error getting booking link: {e}", exc_info=True)
        booking_link = os.getenv("ZENCAL_BOOKING_URL", "https://zencal.io/novahouse/konsultacja")

    context_memory["booking_intent_detected"] = True
    
    # Je≈õli mamy imiƒô, u≈ºyj go
    name = context_memory.get("name", "")
    if name:
        from src.utils.polish_declension import PolishDeclension
        declined_name = PolishDeclension.decline_full_name(name)
        return f"≈öwietnie {declined_name}! üéâ Zarezerwuj bezp≈ÇatnƒÖ konsultacjƒô tutaj: {booking_link}\n\nTo zajmie tylko 2 minuty - wybierz dogodny termin, a nasz ekspert skontaktuje siƒô z TobƒÖ!"
    else:
        return f"≈öwietnie! üéâ Zarezerwuj bezp≈ÇatnƒÖ konsultacjƒô tutaj: {booking_link}\n\nTo zajmie tylko 2 minuty - wybierz dogodny termin, a nasz ekspert skontaktuje siƒô z TobƒÖ!"


@chatbot_bp.route("/health", methods=["GET"])
def chatbot_health():
    """Health check endpoint for chatbot service"""
    return jsonify({"status": "healthy", "service": "chatbot"}), 200


# In-memory fallback storage for context when DB is unavailable
_context_fallback = {}  # {session_id: context_memory}

def process_chat_message(user_message: str, session_id: str) -> dict:
    """
    Process chat message and return bot response
    Used by both REST API and WebSocket

    Args:
        user_message: User's message text
        session_id: Session identifier

    Returns:
        dict with 'response', 'session_id', 'conversation_id'
    """
    conversation = None
    context_memory = {}
    db_available = False
    
    # Try to load from database with timeout
    try:
        # Set a timeout for DB operations (5 seconds)
        import signal
        
        def timeout_handler(signum, frame):
            raise TimeoutError("Database operation timed out")
        
        # Try to get conversation from DB
        try:
            conversation = ChatConversation.query.filter_by(session_id=session_id).first()
            if not conversation:
                conversation = ChatConversation(
                    session_id=session_id,
                    started_at=datetime.now(timezone.utc),
                    context_data=json.dumps({}),
                )
                db.session.add(conversation)
                db.session.commit()

            # Load context with error handling
            try:
                context_memory = json.loads(conversation.context_data or "{}")
                db_available = True
            except (json.JSONDecodeError, TypeError) as e:
                logging.warning(f"Failed to parse context_data for session {session_id}: {e}, using empty dict")
                context_memory = {}
                db_available = True  # DB is available, just bad data
        except (SQLAlchemyError, TimeoutError, Exception) as db_error:
            logging.warning(f"[DB FALLBACK] Database unavailable for session {session_id}: {db_error}")
            db.session.rollback()
            # Use in-memory fallback
            context_memory = _context_fallback.get(session_id, {})
            db_available = False
    except Exception as e:
        logging.warning(f"[DB FALLBACK] Database error, using in-memory storage: {e}")
        db.session.rollback()
        context_memory = _context_fallback.get(session_id, {})
        db_available = False
    
    try:

        # Extract and update context from user message (with safeguards)
        try:
            from src.services.extract_context_safe import extract_context_safe

            context_memory = extract_context_safe(user_message, context_memory)
        except ImportError:
            # Fallback to legacy extract_context if safe version not available
            context_memory = extract_context(user_message, context_memory)
        
        # Save context - try DB first, fallback to in-memory
        if db_available and conversation:
            try:
                conversation.context_data = json.dumps(context_memory, ensure_ascii=False)
                # Try to save user message
                try:
        user_msg = ChatMessage(
            conversation_id=conversation.id,
            message=user_message,
            sender="user",
            timestamp=datetime.now(timezone.utc),
        )
        db.session.add(user_msg)
        db.session.commit()
                except Exception as msg_error:
                    logging.warning(f"[DB] Failed to save message, but continuing: {msg_error}")
                    db.session.rollback()
            except (TypeError, ValueError) as e:
                logging.warning(f"Failed to serialize context_data for session {session_id}: {e}")
                # Try with ensure_ascii=True as fallback
                try:
                    conversation.context_data = json.dumps(context_memory, ensure_ascii=True)
                    db.session.commit()
                except Exception:
                    # Last resort: save minimal context
                    conversation.context_data = json.dumps({"error": "context_serialization_failed"})
                    db.session.commit()
            except Exception as save_error:
                logging.warning(f"[DB] Failed to save context to DB, using in-memory: {save_error}")
                db.session.rollback()
                db_available = False
                # Fall through to in-memory storage
        
        # Always save to in-memory fallback (for redundancy and when DB is down)
        _context_fallback[session_id] = context_memory
        
        # Update session activity
        try:
            from src.services.session_timeout import session_timeout_service
            session_timeout_service.update_activity(session_id)
        except Exception as e:
            logging.warning(f"Failed to update session activity: {e}")

        # Detect if the current message is an introduction (to prioritize GPT routing)
        intro_keywords = ["jestem", "nazywam siƒô", "mam na imiƒô", "to ja", "cze≈õƒá jestem"]
        is_introduction = any(k in user_message.lower() for k in intro_keywords)

        # 1. Check if user wants to book a meeting
        bot_response = check_booking_intent(user_message, context_memory)

        # 2. Check learned FAQs (higher priority - learned from real users)
        if not bot_response:
            bot_response = check_learned_faq(user_message)

        # 3. Then check standard FAQ (skip if this is a self-introduction)
        if not bot_response and not is_introduction:
            bot_response = check_faq(user_message)
        
        # Log if we're using fallback (for debugging)
        if not bot_response:
            logging.debug(f"No FAQ/booking match for: {user_message[:50]}... - will use GPT")

        # 4. Je≈õli nie znaleziono w FAQ, ZAWSZE u≈ºyj AI (OpenAI GPT) - PRIORYTET!
        if not bot_response:
            logging.info(f"[GPT FLOW] No FAQ match for: {user_message[:50]}... - attempting GPT call")
            client = ensure_openai_client()
            if not client:
                # Try direct initialization as fallback
                logging.warning("[WARNING] ensure_openai_client() returned None - trying direct initialization...")
                api_key_check = os.getenv("OPENAI_API_KEY")
                if api_key_check:
                    key_preview = api_key_check[:10] + "..." if len(api_key_check) > 10 else "None"
                    logging.info(f"[DEBUG] OPENAI_API_KEY exists (starts with: {key_preview})")
                else:
                    logging.error("[ERROR] OPENAI_API_KEY is NOT SET in environment!")
                client = get_openai_client()
            if client:
                    logging.info("[INFO] Direct get_openai_client() succeeded")
                else:
                    logging.error("[ERROR] Direct get_openai_client() also returned None!")
            
            if client:
                logging.info(f"[GPT FLOW] OpenAI client available - calling GPT API for: {user_message[:50]}...")
                try:
                    # Pobierz historiƒô konwersacji (ujednolicony limit do 30)
                    message_history_limit = int(os.getenv("MESSAGE_HISTORY_LIMIT", "30"))
                    if db_available and conversation:
                        try:
                    history = (
                        ChatMessage.query.filter_by(conversation_id=conversation.id)
                        .order_by(ChatMessage.timestamp.desc())
                        .limit(message_history_limit)
                        .all()
                    )
                        except Exception:
                            history = []
                    else:
                        history = []

                    context = "\n".join(
                        [
                            f"{'User' if msg.sender == 'user' else 'Bot'}: {msg.message}"
                            for msg in reversed(history[:-1])  # Exclude current message
                        ]
                    )

                    # Add memory context with proper name declension and city recognition
                    memory_prompt = ""
                    if context_memory:
                        from src.utils.polish_declension import PolishDeclension
                        from src.utils.polish_cities import PolishCities

                        memory_items = []
                        if context_memory.get("name"):
                            name = context_memory["name"]
                            declined_name = PolishDeclension.decline_full_name(name)
                            is_polish = PolishDeclension.is_polish_name(name.split()[0])
                            gender = PolishDeclension.detect_gender(name.split()[0])

                            # Add both forms for GPT reference
                            memory_items.append(
                                f"Imiƒô: {name} (wo≈Çacz: {declined_name}, polskie: {is_polish}, p≈Çeƒá: {gender})"
                            )
                        if context_memory.get("city"):
                            city = context_memory["city"]
                            # Check if city is recognized in Polish cities database
                            city_variants = [city, city.title(), city.lower(), city.capitalize()]
                            recognized_city = None
                            for variant in city_variants:
                                if variant in PolishCities.CITIES:
                                    recognized_city = variant
                                    break
                                # Check in ALL_POLISH_CITIES_GUS
                                if variant in PolishCities.ALL_POLISH_CITIES_GUS:
                                    recognized_city = variant
                                    break
                            
                            if recognized_city:
                                memory_items.append(f"Miasto: {recognized_city} (dzia≈Çamy w tym mie≈õcie!)")
                            else:
                                memory_items.append(f"Miasto: {city}")
                        if context_memory.get("square_meters"):
                            memory_items.append(f"Metra≈º: {context_memory['square_meters']}m¬≤")
                        if context_memory.get("budget"):
                            memory_items.append(f"Bud≈ºet: {context_memory['budget']} z≈Ç")
                        if context_memory.get("package"):
                            memory_items.append(f"InteresujƒÖcy pakiet: {context_memory['package']}")
                        
                        # Intelligent package recommendation based on budget and square meters
                        if context_memory.get("budget") and context_memory.get("square_meters"):
                            try:
                                budget = float(context_memory["budget"])
                                sqm = int(context_memory["square_meters"])
                                recommendation = recommend_package(budget, sqm)
                                if recommendation:
                                    memory_items.append(
                                        f"‚≠ê REKOMENDACJA: {recommendation['recommended_package']} "
                                        f"({recommendation['confidence']}% pewno≈õci) - {recommendation['reason']}"
                                    )
                                    # Use recommendation if no package in context
                                    if not context_memory.get("package"):
                                        context_memory["package"] = recommendation["recommended_package"]
                            except (ValueError, TypeError) as e:
                                logging.warning(f"Failed to calculate package recommendation: {e}")
                        
                        # Check if lead has qualification data (recommended_package from qualification form)
                        try:
                            existing_lead = Lead.query.filter_by(session_id=session_id).first()
                            if existing_lead and existing_lead.additional_info:
                                import json
                                try:
                                    qual_data = json.loads(existing_lead.additional_info) if isinstance(existing_lead.additional_info, str) else existing_lead.additional_info
                                    if isinstance(qual_data, dict):
                                        recommended_pkg = qual_data.get("recommended_package")
                                        confidence = qual_data.get("confidence_score")
                                        if recommended_pkg:
                                            # Map qualification package names to chatbot package names
                                            pkg_map = {
                                                "standard": "Express",
                                                "premium": "Comfort",
                                                "luxury": "Premium"
                                            }
                                            chatbot_pkg = pkg_map.get(recommended_pkg.lower(), recommended_pkg)
                                            if confidence:
                                                memory_items.append(f"Rekomendacja z kwalifikacji: {chatbot_pkg} ({confidence}% pewno≈õci)")
                                            else:
                                                memory_items.append(f"Rekomendacja z kwalifikacji: {chatbot_pkg}")
                                            # Use qualification package if no package in context
                                            if not context_memory.get("package"):
                                                context_memory["package"] = chatbot_pkg
                                except (json.JSONDecodeError, AttributeError):
                                    pass
                        except Exception as e:
                            logging.warning(f"[Qualification Data] Error loading: {e}")
                        
                        if memory_items:
                            # Build critical instructions based on what data we have
                            critical_instructions = []
                            
                            # Check if we have name - if user repeats it, confirm it's the same person
                            if context_memory.get("name"):
                                critical_instructions.append(f"‚ö†Ô∏è IMIƒò: Klient poda≈Ç imiƒô '{context_memory.get('name')}'. Je≈õli klient ponownie poda to samo imiƒô - POTWIERD≈π ≈ºe to ta sama osoba i NIE pytaj ponownie o imiƒô!")
                            
                            # Check if we have square_meters - don't ask again
                            if context_memory.get("square_meters"):
                                critical_instructions.append(f"‚ö†Ô∏è METRA≈ª: Klient ju≈º poda≈Ç metra≈º {context_memory.get('square_meters')}m¬≤. NIGDY nie pytaj ponownie o metra≈º - U≈ªYWAJ tego co masz!")
                            
                            # Check if we have package - don't ask again
                            if context_memory.get("package"):
                                critical_instructions.append(f"‚ö†Ô∏è PAKIET: Klient ju≈º wybra≈Ç pakiet '{context_memory.get('package')}'. NIGDY nie pytaj ponownie o pakiet - U≈ªYWAJ tego co masz!")
                            
                            # Check if we have city - don't ask again
                            if context_memory.get("city"):
                                critical_instructions.append(f"‚ö†Ô∏è MIASTO: Klient ju≈º poda≈Ç miasto '{context_memory.get('city')}'. NIGDY nie pytaj ponownie o miasto - U≈ªYWAJ tego co masz!")
                            
                            # Check if we have budget - don't ask again
                            if context_memory.get("budget"):
                                critical_instructions.append(f"‚ö†Ô∏è BUD≈ªET: Klient ju≈º poda≈Ç bud≈ºet {context_memory.get('budget')} z≈Ç. NIGDY nie pytaj ponownie o bud≈ºet - U≈ªYWAJ tego co masz!")
                            
                            # Check if we have email or phone - don't ask again
                            if context_memory.get("email") or context_memory.get("phone"):
                                critical_instructions.append(f"‚ö†Ô∏è KONTAKT: Klient ju≈º poda≈Ç dane kontaktowe. NIGDY nie pytaj ponownie o email/telefon - U≈ªYWAJ tego co masz!")
                            
                            # Build final memory prompt
                            memory_prompt = "\n\nZapamiƒôtane info o kliencie (TYLKO dane kt√≥re klient PODA≈Å WYRA≈πNIE):\n" + "\n".join(
                                memory_items
                            ) + "\n\n"
                            
                            # Add critical instructions
                            if critical_instructions:
                                memory_prompt += "\n".join(critical_instructions) + "\n\n"
                            
                            # Add general instructions
                            memory_prompt += "‚ö†Ô∏è KRYTYCZNE ZASADY:\n"
                            memory_prompt += "- NIGDY nie pytaj o dane kt√≥re JU≈ª MASZ w pamiƒôci powy≈ºej!\n"
                            memory_prompt += "- NIGDY nie zak≈Çadaj danych kt√≥rych klient NIE PODA≈Å!\n"
                            memory_prompt += "- Je≈õli klient m√≥wi 'nie podawa≈Çem X' - USU≈É b≈Çƒôdne dane z pamiƒôci!\n"
                            memory_prompt += "- U≈ºywaj imienia naturalnie (co 2-3 wiadomo≈õci), zapamiƒôtuj miasto i metra≈º, przeliczaj ceny automatycznie!\n"
                            memory_prompt += "- Je≈õli klient ponownie poda imiƒô kt√≥re ju≈º masz - POTWIERD≈π ≈ºe to ta sama osoba (np. 'Tak, rozumiem ≈ºe to Pan/Pani {imiƒô}') i KONTYNUUJ bez pytania o dane kt√≥re ju≈º masz!"

                    # COST OPTIMIZATION: Check cache first for similar questions
                    try:
                        from src.middleware.cache import cache
                        import hashlib
                        # Create cache key from normalized user message (ignore case, whitespace)
                        normalized_msg = user_message.lower().strip()
                        cache_key = f"gpt_response:{hashlib.md5(normalized_msg.encode()).hexdigest()}"
                        cached_response = cache.get(cache_key)
                        if cached_response:
                            logging.debug(f"[GPT CACHE HIT] Using cached response for: {user_message[:50]}...")
                            bot_response = cached_response
                        else:
                            logging.debug(f"[OpenAI GPT] Przetwarzanie: {user_message[:50]}...")
                            messages = [
                                {"role": "system", "content": SYSTEM_PROMPT + memory_prompt},
                                {
                                    "role": "user",
                                    "content": f"Context:\n{context}\n\nUser: {user_message}",
                                },
                            ]
                            # OPTIMIZED FOR COST: Reduced max_tokens from 500 to 350 (saves ~30% on output costs)
                            # Most chatbot responses are 200-300 tokens, 350 is sufficient
                            # CRITICAL: Add timeout to prevent hanging requests
                            # CRITICAL: Use circuit breaker and retry logic
                            from src.services.circuit_breaker import get_openai_circuit_breaker, CircuitBreakerOpenError
                            from src.services.retry_handler import retry_openai_api
                            
                            circuit_breaker = get_openai_circuit_breaker()
                            
                            # Wrap GPT call with retry logic
                            @retry_openai_api
                            def _call_gpt_with_retry():
                                return circuit_breaker.call(
                                    client.chat.completions.create,
                                    model=GPT_MODEL,
                                    messages=messages,
                                    max_tokens=350,  # Optimized: was 500, saves ~30% on output costs
                                    temperature=0.6,  # Optimized: was 0.7, slightly more focused responses
                                    timeout=30.0,  # 30 second timeout to prevent hanging
                                )
                            
                            try:
                                response = _call_gpt_with_retry()
                            except CircuitBreakerOpenError as cb_error:
                                logging.error(f"[CircuitBreaker] Circuit is OPEN: {cb_error}")
                                raise Exception("OpenAI API is temporarily unavailable. Please try again later.")
                            bot_response = response.choices[0].message.content
                            # Validate GPT response
                            if not bot_response or not bot_response.strip():
                                logging.error("[GPT ERROR] Empty response from GPT API!")
                                bot_response = None
                            else:
                                # Cache response for 1 hour (3600s) - common questions get cached
                                cache.set(cache_key, bot_response, ttl=3600)
                                logging.info(f"[OpenAI GPT] Response received: {bot_response[:100] if bot_response else 'EMPTY'}...")
                            # Log token usage for cost tracking
                            if hasattr(response, 'usage'):
                                usage = response.usage
                                logging.debug(f"[GPT COST] Input: {usage.prompt_tokens}, Output: {usage.completion_tokens}, Total: {usage.total_tokens}")
                    except ImportError:
                        # Cache not available, use GPT directly
                        logging.debug(f"[OpenAI GPT] Przetwarzanie (no cache): {user_message[:50]}...")
                    messages = [
                        {"role": "system", "content": SYSTEM_PROMPT + memory_prompt},
                        {
                            "role": "user",
                            "content": f"Context:\n{context}\n\nUser: {user_message}",
                        },
                    ]
                    response = client.chat.completions.create(
                        model=GPT_MODEL,
                        messages=messages,
                            max_tokens=350,
                            temperature=0.6,
                            timeout=30.0,  # 30 second timeout to prevent hanging
                    )
                    bot_response = response.choices[0].message.content
                        # Validate GPT response
                        if not bot_response or not bot_response.strip():
                            logging.error("[GPT ERROR] Empty response from GPT API (no cache)!")
                            bot_response = None
                        else:
                            logging.info(f"[OpenAI GPT] Response received: {bot_response[:100] if bot_response else 'EMPTY'}...")

                except Exception as e:
                    logging.error(f"[GPT ERROR] {type(e).__name__}: {e}", exc_info=True)
                    logging.error(f"[GPT ERROR] Full error details - message: {user_message[:50]}..., client available: {client is not None}")
                    # Fallback tylko przy b≈Çƒôdzie GPT - ale lepszy fallback
                    bot_response = get_default_response(user_message)
                    logging.warning(f"[FALLBACK] Using default response: {bot_response[:50]}...")
            else:
                # Try to get client again - maybe it wasn't initialized yet
                logging.warning("[WARNING] OpenAI client is None - attempting to initialize...")
                client = get_openai_client()
                if client:
                    logging.info("[INFO] OpenAI client initialized successfully - retrying GPT call")
                    try:
                        messages = [
                            {"role": "system", "content": SYSTEM_PROMPT + memory_prompt},
                            {
                                "role": "user",
                                "content": f"Context:\n{context}\n\nUser: {user_message}",
                            },
                        ]
                        response = client.chat.completions.create(
                            model=GPT_MODEL,
                            messages=messages,
                            max_tokens=350,
                            temperature=0.6,
                            timeout=30.0,  # 30 second timeout to prevent hanging
                        )
                        bot_response = response.choices[0].message.content
                        # Validate GPT response
                        if not bot_response or not bot_response.strip():
                            logging.error("[GPT ERROR] Empty response from GPT API (retry)!")
                            bot_response = None
                        else:
                            logging.info(f"[OpenAI GPT] Response received (retry): {bot_response[:100] if bot_response else 'EMPTY'}...")
                    except Exception as e:
                        logging.error(f"[GPT ERROR on retry] {type(e).__name__}: {e}", exc_info=True)
                        logging.error(f"[GPT ERROR on retry] Full error details - message: {user_message[:50]}...")
                bot_response = get_default_response(user_message)
                        logging.warning(f"[FALLBACK] Using default response (retry failed): {bot_response[:50]}...")
                else:
                    # Check if OPENAI_API_KEY is set but client failed to initialize
                    openai_key = os.getenv("OPENAI_API_KEY")
                    if not openai_key or openai_key.lower().startswith("test_"):
                        logging.warning("OPENAI_API_KEY not set or is test key - GPT disabled")
                    else:
                        logging.error(f"OPENAI_API_KEY is set but client initialization failed - check API key validity")
                        logging.error(f"[CRITICAL] GPT is completely unavailable - API key: {bool(openai_key)}, starts with test_: {openai_key.lower().startswith('test_') if openai_key else 'N/A'}")
                    bot_response = get_default_response(user_message)
                    logging.warning(f"[FALLBACK] Using default response (no client): {bot_response[:50]}...")

        # Je≈õli NADAL brak odpowiedzi (nie powinno siƒô zdarzyƒá)
        if not bot_response:
            logging.error("[CRITICAL FALLBACK] U≈ºywam awaryjnej odpowiedzi - brak odpowiedzi z GPT/FAQ")
            logging.error(f"[CRITICAL] Message: {user_message[:50]}..., FAQ match: False, GPT attempted: True")
            bot_response = get_default_response(user_message)
            logging.warning(f"[FALLBACK] Final fallback response: {bot_response[:50]}...")

        # Add proactive booking suggestion if we have data
        if context_memory.get("_booking_suggestion") and not context_memory.get("booking_intent_detected"):
            booking_link = context_memory.pop("_booking_suggestion")
            name = context_memory.get("name", "")
            if name:
                from src.utils.polish_declension import PolishDeclension
                declined_name = PolishDeclension.decline_full_name(name)
                booking_text = f"\n\nüí° {declined_name}, chcesz um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Nasz ekspert dopasuje idealny pakiet do Twojego projektu! Zarezerwuj tutaj: {booking_link}"
            else:
                booking_text = f"\n\nüí° Chcesz um√≥wiƒá bezp≈ÇatnƒÖ konsultacjƒô? Nasz ekspert dopasuje idealny pakiet do Twojego projektu! Zarezerwuj tutaj: {booking_link}"
            bot_response = bot_response + booking_text

        # Track A/B test response (if user responded to follow-up question)
        if conversation.followup_variant and len(user_message) > 3:
            try:
                track_ab_test_response(conversation, user_message)
            except Exception as e:
                logging.warning(f"Failed to track A/B test response: {e}")

        # Check if we just collected enough data to ask for confirmation
        should_confirm = should_ask_for_confirmation(context_memory, conversation)
        logging.debug(f"[CONFIRMATION CHECK] should_confirm={should_confirm}, context={context_memory}, awaiting={conversation.awaiting_confirmation}")
        if should_confirm:
            conversation.awaiting_confirmation = True
            # Use lead creation strategy method or build inline
            confirmation_parts = []
            if context_memory.get("name"):
                confirmation_parts.append(f"Imiƒô: {context_memory['name']}")
            if context_memory.get("email"):
                confirmation_parts.append(f"Email: {context_memory['email']}")
            if context_memory.get("phone"):
                confirmation_parts.append(f"Telefon: {context_memory['phone']}")
            if context_memory.get("city"):
                confirmation_parts.append(f"Miasto: {context_memory['city']}")
            if confirmation_parts:
                confirmation_msg = "Potwierdzam dane:\n" + "\n".join(confirmation_parts)
                bot_response = f"{bot_response}\n\n{confirmation_msg}"
                logging.debug("[CONFIRMATION] Added confirmation message to response")

        # Zapisz odpowied≈∫ bota (only if DB is available)
        if db_available and conversation:
            try:
        bot_msg = ChatMessage(
            conversation_id=conversation.id,
            message=bot_response,
            sender="bot",
            timestamp=datetime.now(timezone.utc),
        )
        db.session.add(bot_msg)
                # Update context in DB
                try:
                    conversation.context_data = json.dumps(context_memory, ensure_ascii=False)
                    db.session.commit()
                except Exception:
                    db.session.rollback()
            except Exception as bot_msg_error:
                logging.warning(f"[DB] Failed to save bot message, but continuing: {bot_msg_error}")
                db.session.rollback()
                # Update in-memory fallback
                _context_fallback[session_id] = context_memory

        # Log unknown/unclear questions for FAQ learning with auto-categorization
        try:
            from src.models.faq_learning import UnknownQuestion

            # Check if response is generic fallback (potential unknown question)
            is_generic = any(
                phrase in bot_response.lower()
                for phrase in [
                    "jak mogƒô ci pom√≥c",
                    "przepraszam",
                    "spr√≥buj ponownie",
                    "nie jestem pewien",
                    "nie rozumiem",
                ]
            )

            # Log if generic response and not FAQ
            if is_generic and not check_faq(user_message):
                # Automatyczne kategoryzowanie pytania
                category = auto_categorize_question(user_message)
                
                unknown = UnknownQuestion(
                    session_id=session_id,
                    question=user_message,
                    bot_response=bot_response,
                    status="pending",
                    category=category,
                )
                db.session.add(unknown)
        except Exception as e:
            logging.warning(f"[FAQ Learning] Failed to log: {e}", exc_info=True)
            # Don't fail the main flow

        # Check if user is confirming data
        confirmation_intent = check_data_confirmation_intent(user_message)
        # Safe query with error handling for missing columns
        try:
        existing_lead = Lead.query.filter_by(session_id=session_id).first()
        except Exception as e:
            logging.warning(f"Failed to query Lead for session {session_id}: {e}")
            existing_lead = None

        # Check if we have enough data to create lead
        has_enough_data_for_lead = context_memory.get("name") and (
            context_memory.get("email") or context_memory.get("phone")
        )

        if confirmation_intent == "confirm" and has_enough_data_for_lead and not existing_lead:
            # User confirmed - create lead now
            try:
                if not existing_lead:
                    from src.integrations.monday_client import MondayClient

                    # Get message count for lead scoring
                    if db_available and conversation:
                        try:
                    message_count = ChatMessage.query.filter_by(
                        conversation_id=conversation.id
                    ).count()
                    # Generate conversation summary
                    all_messages = (
                        ChatMessage.query.filter_by(conversation_id=conversation.id)
                        .order_by(ChatMessage.timestamp.asc())
                        .all()
                    )
                    conv_summary = generate_conversation_summary(all_messages, context_memory)
                        except Exception:
                            message_count = 0
                            conv_summary = f"Konwersacja z chatbotem. Dane: {json.dumps(context_memory, ensure_ascii=False)}"
                    else:
                        message_count = 0
                        conv_summary = f"Konwersacja z chatbotem. Dane: {json.dumps(context_memory, ensure_ascii=False)}"
                    
                    lead_score = calculate_lead_score(context_memory, message_count)

                    # Create lead
                    lead = Lead(
                        session_id=session_id,
                        name=context_memory.get("name", "Unknown"),
                        email=context_memory.get("email"),
                        phone=context_memory.get("phone"),
                        location=context_memory.get("city"),
                        property_size=context_memory.get("square_meters"),
                        interested_package=context_memory.get("package"),
                        source="chatbot",
                        status="qualified",  # User confirmed data
                        lead_score=lead_score,
                        conversation_summary=conv_summary,
                        data_confirmed=True,
                        last_interaction=datetime.now(timezone.utc),
                    )

                    db.session.add(lead)
                    db.session.flush()

                    # Generate next action recommendation
                    next_action = suggest_next_best_action(context_memory, lead_score)
                    lead.notes = f"Next Action: {next_action}"

                    # Check for competitive mentions
                    competitor_intel = (
                        CompetitiveIntel.query.filter_by(session_id=session_id)
                        .order_by(CompetitiveIntel.created_at.desc())
                        .first()
                    )
                    competitor_name = competitor_intel.competitor_name if competitor_intel else None

                    # Sync with Monday.com
                    monday = MondayClient(api_key=MONDAY_API_KEY)
                    monday_item_id = monday.create_lead_item(
                        {
                            "name": lead.name,
                            "email": lead.email,
                            "phone": lead.phone,
                            "message": f"Lead Score: {lead_score}/100 | {conv_summary} | Action: {next_action}",
                            "property_type": "Mieszkanie",
                            "budget": context_memory.get("square_meters", ""),
                            "lead_score": lead_score,
                            "competitor_mentioned": competitor_name,
                            "next_action": next_action,
                        }
                    )

                    if monday_item_id:
                        lead.monday_item_id = monday_item_id
                        logging.info(f"[Monday] Confirmed lead created: {monday_item_id} (score: {lead_score})")
                        logging.info(f"Lead created in Monday.com: {lead.name}, score: {lead_score}")

                    # Alert dla lead√≥w o wysokim priorytecie
                    if lead_score >= 70:
                        try:
                            from src.services.email_service import email_service

                            email_service.send_email(
                                to_email=os.getenv("ADMIN_EMAIL", "admin@novahouse.pl"),
                                subject=f"üî• HIGH PRIORITY LEAD - Score: {lead_score}/100",
                                html_content=f"""
                                <h2>New High-Priority Lead!</h2>
                                <p><strong>Name:</strong> {lead.name}</p>
                                <p><strong>Email:</strong> {lead.email}</p>
                                <p><strong>Score:</strong> {lead_score}</p>
                                <p><strong>Monday.com ID:</strong> {monday_item_id}</p>
                                """,
                            )
                            logging.info(f"ALERT: High-priority lead: {lead.name}, score: {lead_score}")
                        except Exception as e:
                            logging.error(f"Failed to send high-priority alert: {e}", exc_info=True)

                    # Clear awaiting flag
                    conversation.awaiting_confirmation = False

                    # Add confirmation message to bot response
                    bot_response = (
                        f"‚úÖ Dziƒôkujƒô za potwierdzenie! Twoje dane zosta≈Çy zapisane.\n\n"
                        f"Nasz zesp√≥≈Ç skontaktuje siƒô z TobƒÖ wkr√≥tce.\n\n"
                        f"{bot_response}"
                    )

            except Exception as e:
                logging.error(f"[Confirmed Lead] Error: {e}", exc_info=True)

        elif confirmation_intent == "edit":
            # User wants to edit - clear awaiting flag
            conversation.awaiting_confirmation = False
            bot_response = "Oczywi≈õcie! Popraw dane kt√≥re chcesz zmieniƒá, a ja je zaktualizujƒô. üìù"

        # Fallback: Auto-create lead if enough data (no confirmation asked)
        # Create lead automatically if we have contact data OR high lead score
        elif not conversation.awaiting_confirmation and not existing_lead:
            try:
                has_contact_data = (
                    context_memory.get("name")
                    and (context_memory.get("email") or context_memory.get("phone"))
                )

                # Also create lead if we have project data (metra≈º/bud≈ºet) even without contact
                # This allows us to capture leads earlier
                has_project_data = context_memory.get("square_meters") or context_memory.get("budget")

                # Calculate lead score first to decide
                    message_count = ChatMessage.query.filter_by(
                        conversation_id=conversation.id
                    ).count()
                    lead_score = calculate_lead_score(context_memory, message_count)
                
                # Create lead if:
                # 1. We have contact data (name + email/phone)
                # 2. OR we have project data (metra≈º/bud≈ºet) AND lead score >= 30
                should_create_lead = has_contact_data or (has_project_data and lead_score >= 30)

                if should_create_lead:
                    from src.integrations.monday_client import MondayClient

                    # message_count and lead_score already calculated above

                    all_messages = (
                        ChatMessage.query.filter_by(conversation_id=conversation.id)
                        .order_by(ChatMessage.timestamp.asc())
                        .all()
                    )
                    conv_summary = generate_conversation_summary(all_messages, context_memory)

                    lead = Lead(
                        session_id=session_id,
                        name=context_memory.get("name", "Unknown"),
                        email=context_memory.get("email"),
                        phone=context_memory.get("phone"),
                        location=context_memory.get("city"),
                        property_size=context_memory.get("square_meters"),
                        interested_package=context_memory.get("package"),
                        source="chatbot",
                        status="new",
                        lead_score=lead_score,
                        conversation_summary=conv_summary,
                        data_confirmed=False,
                        last_interaction=datetime.now(timezone.utc),
                    )

                    db.session.add(lead)
                    db.session.flush()

                    # Check for competitive mentions
                    competitor_intel = (
                        CompetitiveIntel.query.filter_by(session_id=session_id)
                        .order_by(CompetitiveIntel.created_at.desc())
                        .first()
                    )
                    competitor_name = competitor_intel.competitor_name if competitor_intel else None
                    next_action = suggest_next_best_action(context_memory, lead_score)

                    monday = MondayClient(api_key=MONDAY_API_KEY)
                    monday_item_id = monday.create_lead_item(
                        {
                            "name": lead.name,
                            "email": lead.email,
                            "phone": lead.phone,
                            "message": f"Lead Score: {lead_score}/100 | {conv_summary}",
                            "property_type": "Mieszkanie",
                            "budget": context_memory.get("square_meters", ""),
                            "lead_score": lead_score,
                            "competitor_mentioned": competitor_name,
                            "next_action": next_action,
                        }
                    )

                    if monday_item_id:
                        lead.monday_item_id = monday_item_id
                        logging.info(f"[Monday] Auto-lead created: {monday_item_id} (score: {lead_score})")

            except Exception as e:
                logging.error(f"[Auto Lead] Error: {e}", exc_info=True)

        db.session.commit()

        # Check for competitive intelligence
        detect_competitive_intelligence(user_message, session_id, context_memory)

        # Generate intelligent follow-up question (with A/B testing)
        follow_up = generate_intelligent_follow_up(
            context_memory, user_message, bot_response, conversation
        )
        if follow_up:
            bot_response = f"{bot_response}\n\n{follow_up}"

        # Calculate lead score (use in-memory message count if DB unavailable)
        if db_available and conversation:
            try:
        message_count = ChatMessage.query.filter_by(conversation_id=conversation.id).count()
            except Exception:
                message_count = 0
        else:
            message_count = 0  # Approximate when DB unavailable
        
        lead_score = calculate_lead_score(context_memory, message_count)
        next_action = suggest_next_best_action(context_memory, lead_score)

        return {
            "response": bot_response,
            "session_id": session_id,
            "conversation_id": conversation.id if conversation else None,
            "context": context_memory,
            "lead_score": lead_score,
            "next_best_action": next_action,
        }

    except SQLAlchemyError as e:
        logging.error(f"Database error in chat processing: {e}", exc_info=True)
        db.session.rollback()
        # Try to continue without database (graceful degradation)
        # CRITICAL: Even if database fails, try to use GPT for response
        try:
            logging.warning("[DB ERROR] Database failed, but attempting GPT response anyway...")
            # Try to get GPT response even without database
            client = ensure_openai_client()
            if not client:
                client = get_openai_client()
            
            if client:
                try:
                    # Use GPT even without database context
                    messages = [
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user", "content": user_message},
                    ]
                    response = client.chat.completions.create(
                        model=GPT_MODEL,
                        messages=messages,
                        max_tokens=350,
                        temperature=0.6,
                        timeout=30.0,  # 30 second timeout to prevent hanging
                    )
                    bot_response = response.choices[0].message.content
                    if bot_response and bot_response.strip():
                        logging.info(f"[GPT SUCCESS] Got response despite DB error: {bot_response[:50]}...")
        return {
                            "response": bot_response,
                            "session_id": session_id,
                            "conversation_id": None,
                        }
                except Exception as gpt_error:
                    logging.error(f"[GPT ERROR in DB fallback] {gpt_error}", exc_info=True)
            
            # If GPT also failed, use basic fallback
            logging.warning("[FALLBACK] Both DB and GPT failed, using basic response")
            return {
                "response": "Dziƒôkujƒô za wiadomo≈õƒá! Jak mogƒô pom√≥c w wyko≈Ñczeniu Twojego mieszkania? Mo≈ºesz zapytaƒá o ofertƒô, pakiety lub terminy realizacji.",
                "session_id": session_id,
                "conversation_id": None,
            }
        except Exception as fallback_error:
            logging.error(f"Fallback also failed: {fallback_error}", exc_info=True)
            return {
                "response": "Przepraszam, problem z bazƒÖ danych. Spr√≥buj ponownie za chwilƒô.",
            "session_id": session_id,
            "conversation_id": None,
        }
    except Exception as e:
        logging.error(f"[CRITICAL] Unexpected chat processing error: {e}", exc_info=True)
        db.session.rollback()
        # Try to get GPT response even on unexpected errors
        try:
            client = ensure_openai_client()
            if not client:
                client = get_openai_client()
            if client:
                try:
                    messages = [
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user", "content": user_message},
                    ]
                    response = client.chat.completions.create(
                        model=GPT_MODEL,
                        messages=messages,
                        max_tokens=350,
                        temperature=0.6,
                        timeout=30.0,  # 30 second timeout
                    )
                    bot_response = response.choices[0].message.content
                    if bot_response and bot_response.strip():
                        logging.info(f"[GPT SUCCESS] Got response despite unexpected error: {bot_response[:50]}...")
        return {
                            "response": bot_response,
            "session_id": session_id,
            "conversation_id": None,
                        }
                except Exception as gpt_error:
                    logging.error(f"[GPT ERROR in unexpected error handler] {gpt_error}", exc_info=True)
        except Exception as fallback_error:
            logging.error(f"[FALLBACK ERROR] Even GPT fallback failed: {fallback_error}", exc_info=True)
        
        return {
            "response": "Dziƒôkujƒô za wiadomo≈õƒá! Jak mogƒô pom√≥c w wyko≈Ñczeniu Twojego mieszkania? Mo≈ºesz zapytaƒá o ofertƒô, pakiety lub terminy realizacji.",
            "session_id": session_id,
            "conversation_id": None,
        }


def _check_admin_key():
    """Return None if ok, or (response, status) tuple if unauthorized."""
    from flask import request

    admin_key = os.getenv("ADMIN_API_KEY")
    if not admin_key:
        return None
    header = request.headers.get("X-ADMIN-API-KEY") or request.headers.get("X-API-KEY")
    if header == admin_key:
        return None
    return (jsonify({"error": "Unauthorized"}), 401)


# Konfiguracja AI (OpenAI GPT + Monday.com)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
MONDAY_API_KEY = os.getenv("MONDAY_API_KEY", "")

# Lazy initialize OpenAI client
openai_client = None
AI_PROVIDER = None


def ensure_openai_client():
    """Ensure OpenAI client is initialized (lazy loading)"""
    global openai_client, AI_PROVIDER
    gpt_enabled = os.getenv("GPT_FALLBACK_ENABLED", "true").lower() == "true"
    if not gpt_enabled:
        logging.warning("‚ö†Ô∏è  GPT_FALLBACK_ENABLED=false ‚Äì skipping GPT client init")
        return None

    # Get API key from environment (always fresh, not from global variable)
    api_key = os.getenv("OPENAI_API_KEY")
    
    # Always try to get client (even if already initialized, to ensure it's working)
    if api_key and not api_key.lower().startswith("test_"):
        client = get_openai_client()
        if client:
            openai_client = client
            AI_PROVIDER = "openai"
            logging.debug("‚úÖ OpenAI GPT-4o-mini client ready")
    return openai_client
        else:
            logging.warning("‚ö†Ô∏è  get_openai_client() returned None - check API key validity")
            return None
    else:
        # SECURITY: Never log full API key, only first 4 chars for debugging
        key_preview = api_key[:4] + "..." if api_key and len(api_key) > 4 else "None"
        logging.warning(f"‚ö†Ô∏è  OPENAI_API_KEY missing/placeholder (key starts with: {key_preview}) ‚Äì GPT disabled")
        return None


if MONDAY_API_KEY:
    logging.info("‚úÖ Monday.com API key loaded")
else:
    logging.warning("‚ö†Ô∏è  No Monday.com API key - set MONDAY_API_KEY")


@chatbot_bp.route("/chat", methods=["POST"])
@limiter.limit(lambda: os.getenv("CHAT_RATE_LIMIT", "30 per minute"))
def chat():
    """Handle chat messages via REST API (NEW: with state machine, validation, rate limiting)"""
    # Check IP blacklist
    from src.services.ip_blacklist import ip_blacklist
    
    ip_address = request.remote_addr or "unknown"
    if ip_blacklist.is_blacklisted(ip_address):
        return jsonify({
            "error": "ip_blacklisted",
            "message": "Your IP has been temporarily blocked due to rate limit violations"
        }), 403
    
    # Check minimum interval between messages
    from src.services.rate_limiter import ensure_rate_limiter
    
    payload = request.get_json(silent=True) or {}
    session_id = payload.get("session_id") or "unknown"
    
    try:
        limiter = ensure_rate_limiter()
        min_interval = int(os.getenv("MIN_MESSAGE_INTERVAL_SECONDS", "1"))
        allowed, wait_seconds = limiter.check_minimum_interval(
            f"session:{session_id}",
            min_interval
        )
        if not allowed:
            return jsonify({
                "error": "message_too_fast",
                "message": f"Please wait {wait_seconds} seconds before sending another message",
                "retry_after": wait_seconds
            }), 429
    except Exception as e:
        # Fail open if limiter unavailable
        logging.warning(f"Minimum interval check failed: {e}")
    
    payload = request.get_json(silent=True) or {}

    # Validate payload using validator
    from src.utils.validators import validate_chat_payload
    
    try:
        user_message, session_id = validate_chat_payload(payload)
    except (ValidationError, ChatMessageTooLongError) as e:
        # These are business errors, will be handled by global error handler
        raise
    
    # Generate session_id if not provided
    if not session_id:
        session_id = str(uuid.uuid4())

    try:
        from src.services.monitoring import track_request, MetricsService, capture_exception
        
        with track_request("/chat"):
            response_data = process_chat_message(user_message, session_id)
            MetricsService.increment_conversation("success")
    except Exception as e:  # pragma: no cover - defensive
        # Let business exceptions propagate to global handler
        from src.exceptions import BusinessException
        if isinstance(e, BusinessException):
            raise
        
        from src.services.monitoring import MetricsService, capture_exception
        from flask import g
        
        MetricsService.increment_error(500)
        MetricsService.increment_conversation("error")
        capture_exception(e, extra={"session_id": session_id})
        
        logging.exception("Error in chat endpoint")
        
        # Re-raise to be caught by global handler
        raise

    return jsonify(
        {
            "response": response_data.get("response"),
            "session_id": session_id,
            "conversation_id": response_data.get("conversation_id"),
            "context": response_data.get("context"),
            "lead_score": response_data.get("lead_score"),
            "next_best_action": response_data.get("next_best_action"),
            "alerts": response_data.get("alerts", []),
        }
    )


@chatbot_bp.route("/history/<session_id>", methods=["GET"])
def get_history(session_id):
    """Get conversation history"""
    try:
        conversation = ChatConversation.query.filter_by(session_id=session_id).first()

        if not conversation:
            return jsonify({"messages": []}), 200

        messages = (
            ChatMessage.query.filter_by(conversation_id=conversation.id)
            .order_by(ChatMessage.timestamp.asc())
            .all()
        )

        return (
            jsonify(
                {
                    "messages": [
                        {
                            "message": msg.message,
                            "sender": msg.sender,
                            "timestamp": msg.timestamp.isoformat(),
                        }
                        for msg in messages
                    ]
                }
            ),
            200,
        )

    except Exception as e:
        return jsonify({"error": str(e)}), 500


@chatbot_bp.route("/rodo-consent", methods=["POST"])
def save_rodo_consent():
    """Zapisz zgodƒô RODO u≈ºytkownika"""
    try:
        data = request.get_json()
        session_id = data.get("session_id")

        if not session_id:
            return jsonify({"error": "Session ID is required"}), 400

        # Sprawd≈∫ czy zgoda ju≈º istnieje
        existing_consent = RodoConsent.query.filter_by(session_id=session_id).first()

        if existing_consent:
            return jsonify({"success": True, "message": "Zgoda RODO ju≈º zapisana"}), 200

        # Zapisz nowƒÖ zgodƒô
        consent = RodoConsent(
            session_id=session_id,
            consent_given=data.get("consent_given", True),
            consent_date=datetime.now(timezone.utc),
            ip_address=request.remote_addr,
            user_agent=request.headers.get("User-Agent", "")[:500],
        )

        db.session.add(consent)
        db.session.commit()

        return jsonify({"success": True, "message": "Zgoda RODO zapisana pomy≈õlnie"}), 200

    except Exception as e:
        db.session.rollback()
        logging.error(f"Error saving RODO consent: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500


@chatbot_bp.route("/delete-my-data", methods=["DELETE"])
def delete_user_data():
    """Usu≈Ñ dane u≈ºytkownika (prawo do bycia zapomnianym - RODO Art. 17)"""
    try:
        data = request.get_json()
        session_id = data.get("session_id")

        if not session_id:
            return jsonify({"error": "Session ID is required"}), 400

        # Usu≈Ñ konwersacjƒô i wszystkie powiƒÖzane wiadomo≈õci (cascade)
        conversation = ChatConversation.query.filter_by(session_id=session_id).first()
        if conversation:
            db.session.delete(conversation)

        # Usu≈Ñ leady powiƒÖzane z sesjƒÖ
        Lead.query.filter_by(session_id=session_id).delete()

        # Usu≈Ñ zgodƒô RODO
        RodoConsent.query.filter_by(session_id=session_id).delete()

        db.session.commit()

        # Audit the deletion
        try:
            audit = AuditLog(
                action="delete",
                session_id=session_id,
                ip_address=request.remote_addr,
                details=f"Deleted conversation and related leads/consent for session {session_id}",
            )
            db.session.add(audit)
            db.session.commit()
        except Exception as e:
            logging.warning(f"[RODO] Warning: Failed to log audit entry: {e}", exc_info=True)
            db.session.rollback()

        return (
            jsonify(
                {"success": True, "message": "Wszystkie Twoje dane zosta≈Çy usuniƒôte zgodnie z RODO"}
            ),
            200,
        )

    except Exception as e:
        db.session.rollback()
        logging.error(f"Error deleting user data: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500


@chatbot_bp.route("/rodo-consent/<session_id>", methods=["GET"])
def get_rodo_consent(session_id):
    """Pobierz zapis zgody RODO dla danej sesji"""
    try:
        consent = RodoConsent.query.filter_by(session_id=session_id).first()
        if not consent:
            return jsonify({"error": "Consent not found"}), 404
        return jsonify(consent.to_dict()), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@chatbot_bp.route("/consents", methods=["GET"])
def list_consents():
    """Admin endpoint: list consents with simple pagination (admin key required)"""
    unauthorized = _check_admin_key()
    if unauthorized:
        return unauthorized

    try:
        page = int(request.args.get("page", 1))
        per_page = int(request.args.get("per_page", 50))
        query = RodoConsent.query.order_by(RodoConsent.consent_date.desc())
        total = query.count()
        items = query.limit(per_page).offset((page - 1) * per_page).all()
        return (
            jsonify(
                {
                    "page": page,
                    "per_page": per_page,
                    "total": total,
                    "consents": [c.to_dict() for c in items],
                }
            ),
            200,
        )
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@chatbot_bp.route("/audit", methods=["GET"])
def list_audit():
    """Admin endpoint: list audit logs with pagination and optional filters"""
    unauthorized = _check_admin_key()
    if unauthorized:
        return unauthorized

    try:
        page = int(request.args.get("page", 1))
        per_page = int(request.args.get("per_page", 50))
        action = request.args.get("action")
        session_id = request.args.get("session_id")

        query = AuditLog.query
        if action:
            query = query.filter(AuditLog.action == action)
        if session_id:
            query = query.filter(AuditLog.session_id == session_id)

        total = query.count()
        items = (
            query.order_by(AuditLog.timestamp.desc())
            .limit(per_page)
            .offset((page - 1) * per_page)
            .all()
        )

        return (
            jsonify(
                {
                    "page": page,
                    "per_page": per_page,
                    "total": total,
                    "items": [a.to_dict() for a in items],
                }
            ),
            200,
        )
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@chatbot_bp.route("/audit/cleanup", methods=["POST"])
def cleanup_audit_endpoint():
    """Admin endpoint to cleanup audit logs older than N days (default 90)."""
    unauthorized = _check_admin_key()
    if unauthorized:
        return unauthorized

    try:
        data = request.get_json() or {}
        days = int(data.get("days", 90))
        cutoff = datetime.now(timezone.utc) - timedelta(days=days)

        deleted = AuditLog.query.filter(AuditLog.timestamp < cutoff).delete()
        db.session.commit()

        # record audit of cleanup
        try:
            audit = AuditLog(
                action="cleanup",
                session_id=None,
                ip_address=request.remote_addr,
                details=f"Purged {deleted} audit logs older than {days} days",
            )
            db.session.add(audit)
            db.session.commit()
        except Exception as e:
            logging.warning(f"[RODO] Warning: Failed to log cleanup audit entry: {e}", exc_info=True)
            db.session.rollback()

        return jsonify({"deleted": deleted}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@chatbot_bp.route("/export-data/<session_id>", methods=["GET"])
def export_user_data(session_id):
    """Eksportuj wszystkie dane powiƒÖzane z sesjƒÖ (konwersacje, wiadomo≈õci, leady, zgoda)"""
    # optional admin key check
    unauthorized = _check_admin_key()
    if unauthorized:
        return unauthorized

    try:
        conversation = ChatConversation.query.filter_by(session_id=session_id).first()
        messages = []
        if conversation:
            msgs = (
                ChatMessage.query.filter_by(conversation_id=conversation.id)
                .order_by(ChatMessage.timestamp.asc())
                .all()
            )
            messages = [
                {
                    "id": m.id,
                    "message": m.message,
                    "sender": m.sender,
                    "timestamp": m.timestamp.isoformat(),
                }
                for m in msgs
            ]

        leads = [l.to_dict() for l in Lead.query.filter_by(session_id=session_id).all()]
        consent = RodoConsent.query.filter_by(session_id=session_id).first()

        result = {
            "session_id": session_id,
            "conversation_id": conversation.id if conversation else None,
            "messages": messages,
            "leads": leads,
            "consent": consent.to_dict() if consent else None,
        }

        # Audit the export (if AuditLog table exists)
        try:
            audit = AuditLog(
                action="export",
                session_id=session_id,
                ip_address=request.remote_addr,
                details=f"Exported data for session {session_id}",
            )
            db.session.add(audit)
            db.session.commit()
        except Exception as e:
            # Rollback but don't fail the export if audit fails
            logging.warning(f"[RODO] Warning: Failed to log export audit entry: {e}", exc_info=True)
            db.session.rollback()

        return jsonify(result), 200
    except Exception as e:
        db.session.rollback()
        return jsonify({"error": str(e)}), 500


@chatbot_bp.route("/monday-test", methods=["POST"])
def monday_test():
    """Test Monday.com connection and create test item"""
    # Admin key check
    auth_error = _check_admin_key()
    if auth_error:
        return auth_error

    try:
        from src.integrations.monday_client import MondayClient

        monday = MondayClient()

        # Test connection
        if not monday.test_connection():
            return jsonify({"error": "Failed to connect to Monday.com"}), 500

        # Create test item
        test_data = {
            "name": "Test Lead - Novahouse Chatbot",
            "email": "test@novahouse.pl",
            "phone": "123456789",
            "message": "Test integration from chatbot",
            "recommended_package": "premium",
            "confidence_score": 90.0,
            "property_type": "Dom",
            "budget": "150000",
            "interior_style": "Nowoczesny",
        }

        item_id = monday.create_lead_item(test_data)

        if not item_id:
            return jsonify({"error": "Failed to create test item"}), 500

        return (
            jsonify(
                {
                    "message": "Monday.com connection successful",
                    "test_item_id": item_id,
                    "api_key_set": bool(monday.api_key),
                    "board_id_set": bool(monday.board_id),
                }
            ),
            200,
        )

    except Exception as e:
        return jsonify({"error": str(e)}), 500


@chatbot_bp.route("/ab-tests/results", methods=["GET"])
def get_ab_test_results():
    """
    Get A/B testing results for follow-up questions
    Requires admin key
    """
    admin_key = os.getenv("ADMIN_API_KEY") or os.getenv("API_KEY")
    if admin_key:
        header = request.headers.get("X-ADMIN-API-KEY") or request.headers.get("X-API-KEY")
        if header != admin_key:
            return jsonify({"error": "Unauthorized"}), 401

    try:
        tests = FollowUpTest.query.all()
        results = []

        for test in tests:
            test_data = test.to_dict()

            # Statistical significance check (basic)
            total_shown = test.variant_a_shown + test.variant_b_shown
            if total_shown >= 100:  # Minimum sample size
                conv_a = test_data["stats"]["variant_a"]["conversion_rate"] or 0
                conv_b = test_data["stats"]["variant_b"]["conversion_rate"] or 0

                if abs(conv_a - conv_b) > 10:  # 10% difference threshold
                    winner = "A" if conv_a > conv_b else "B"
                    test_data["winner"] = winner
                    test_data["significance"] = "statistically significant"
                else:
                    test_data["winner"] = "inconclusive"
                    test_data["significance"] = "no significant difference"
            else:
                test_data["winner"] = "insufficient data"
                test_data["significance"] = f"need {100 - total_shown} more impressions"

            results.append(test_data)

        return jsonify({"tests": results}), 200

    except Exception as e:
        return jsonify({"error": str(e)}), 500


@chatbot_bp.route("/ab-tests/create", methods=["POST"])
def create_ab_test():
    """
    Create new A/B test for follow-up questions
    Requires admin key
    """
    admin_key = os.getenv("ADMIN_API_KEY") or os.getenv("API_KEY")
    if admin_key:
        header = request.headers.get("X-ADMIN-API-KEY") or request.headers.get("X-API-KEY")
        if header != admin_key:
            return jsonify({"error": "Unauthorized"}), 401

    try:
        data = request.get_json()

        test = FollowUpTest(
            question_type=data.get("question_type"),
            variant_a=data.get("variant_a"),
            variant_b=data.get("variant_b"),
            is_active=data.get("is_active", True),
        )

        db.session.add(test)
        db.session.commit()

        return jsonify({"message": "A/B test created", "test_id": test.id}), 201

    except Exception as e:
        db.session.rollback()
        return jsonify({"error": str(e)}), 500


@chatbot_bp.route("/competitive-intelligence", methods=["GET"])
def get_competitive_intelligence():
    """
    Get competitive intelligence insights from conversations
    Requires admin key
    """
    admin_key = os.getenv("ADMIN_API_KEY") or os.getenv("API_KEY")
    if admin_key:
        header = request.headers.get("X-ADMIN-API-KEY") or request.headers.get("X-API-KEY")
        if header != admin_key:
            return jsonify({"error": "Unauthorized"}), 401

    try:
        from datetime import timedelta

        # Get time range from query params (default: last 30 days)
        days = request.args.get("days", 30, type=int)
        since = datetime.now(timezone.utc) - timedelta(days=days)

        # Get all intel
        intel_records = CompetitiveIntel.query.filter(CompetitiveIntel.created_at >= since).all()

        # Aggregated stats
        total_mentions = len(intel_records)
        competitor_counts = {}
        intel_type_counts = {}
        sentiment_counts = {"positive": 0, "negative": 0, "neutral": 0}
        priority_counts = {"high": 0, "medium": 0, "low": 0}

        for intel in intel_records:
            # Count by competitor
            if intel.competitor_name:
                competitor_counts[intel.competitor_name] = (
                    competitor_counts.get(intel.competitor_name, 0) + 1
                )

            # Count by type
            intel_type_counts[intel.intel_type] = intel_type_counts.get(intel.intel_type, 0) + 1

            # Count by sentiment
            sentiment_counts[intel.sentiment] = sentiment_counts.get(intel.sentiment, 0) + 1

            # Count by priority
            priority_counts[intel.priority] = priority_counts.get(intel.priority, 0) + 1

        # Recent high-priority intel (last 10)
        recent_high_priority = (
            CompetitiveIntel.query.filter(CompetitiveIntel.priority == "high")
            .order_by(CompetitiveIntel.created_at.desc())
            .limit(10)
            .all()
        )

        return (
            jsonify(
                {
                    "summary": {
                        "total_mentions": total_mentions,
                        "date_range_days": days,
                        "competitor_mentions": competitor_counts,
                        "intel_types": intel_type_counts,
                        "sentiment_distribution": sentiment_counts,
                        "priority_distribution": priority_counts,
                    },
                    "recent_high_priority": [intel.to_dict() for intel in recent_high_priority],
                }
            ),
            200,
        )

    except Exception as e:
        return jsonify({"error": str(e)}), 500
